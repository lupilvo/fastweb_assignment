{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe95a70",
   "metadata": {},
   "source": [
    "## Bank Term Deposit Acceptance forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ecf920",
   "metadata": {},
   "source": [
    "Obiettivo di questo assignment è la valutazione delle competenze tecniche del candidato e la sua modalità di approccio ad un problema di Data Science. Nello specifico è richiesto di sviluppare un modello predittivo in grado di indicare se un cliente intercettato da una campagna di marketing da parte di una banca decide di sottoscrivere o meno un deposito bancario a termine (bank term deposit).\n",
    "\n",
    "#### Dataset: ####\n",
    "\n",
    "All'interno della cartella **data**  viene fornito il file **bank-dataset.csv** che contiene le campagne marketing telefoniche effettuate da una banca per proporre l'acquisto del prodotto bancario.\n",
    "I dettagli del dataset sono forniti all'interno del file: **bank-names.txt**.\n",
    "La variabile target che indica se il cliente accetta o meno la sottoscrizione del deposito bancario è contenuta nel medesimo file con field name \"y\".\n",
    "\n",
    "#### Assignement: ####\n",
    "\n",
    "Richiesta di questo assignment è la costruzione di un modello predittivo con performance soddisfacenti per il candidato dando evidenza di tutti gli step tipici che dovrebbero essere affrontati in un progetto di Data Science: dalla pulizia e preparazione del dato fino al testing delle performance del modello costruito.\n",
    "\n",
    "Il notebook svolto dovrà essere opportunamente commentato e dovrà essere consegnato tramite condivisione di un repository github personale accessibile che ne permetta la riproduzione."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac139701",
   "metadata": {},
   "source": [
    "### Import library and custom funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f56a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cf7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_values(df, col, **kwargs):\n",
    "    \"\"\"\n",
    "    Function than wrap pandas value_counts functions in order to check multiple columns\n",
    "    :param df: input dataframe\n",
    "    :param col: selected column\n",
    "    :param **kwargs: pandas value_counts params\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nColumn: {col}\\n\")\n",
    "    print(df[col].value_counts(**kwargs))\n",
    "    print(\"#\"*100)\n",
    "    \n",
    "def normalize_col(df, col, nan_value=\"unknown\"):\n",
    "    \"\"\"\n",
    "    Apply lower case and replace nan value to a column\n",
    "    :param df: input dataframe\n",
    "    :param col: selected column\n",
    "    :param nan_value: value to replace in nan (default: 'unknown')\n",
    "    :return dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    df[col] = df[col].str.lower()\n",
    "    df[col] = df[col].replace(np.nan, 0)\n",
    "\n",
    "    return df\n",
    "\n",
    "def replace_missing(df):\n",
    "    \"\"\"\n",
    "    Check and replace missing value with mode\n",
    "    :param df: input dataframe\n",
    "    :return dataframe\n",
    "    \"\"\"\n",
    "        \n",
    "    for col in df.columns:\n",
    "        isna = df[col].isna().values.any()\n",
    "        if isna:\n",
    "            new_value = df[col].mode()[0]\n",
    "            df[col] = df[col].fillna(new_value)\n",
    "            print(f\"Replaced {col} missing value with nan values: {new_value}\")   \n",
    "        \n",
    "    return df\n",
    "\n",
    "def plot_correlation_matrix(df, single_corner=False, target=None):\n",
    "    \"\"\"\n",
    "    Plot correlation matrix with option to convert target column and plot half matrix \n",
    "    :param df: input dataframe\n",
    "    :param single_corner: boolean to plot only half matrix (default: False)\n",
    "    :param target: name of target column to convert into numerical column (default: None)\n",
    "    \"\"\"\n",
    "    \n",
    "    df_corr = df.copy()\n",
    "    if target:\n",
    "        binary_map = {\"no\": 0, \"yes\": 1}\n",
    "        df_corr[target] = df_corr[target].map(binary_map)\n",
    "        \n",
    "    df_corr = df_corr.corr()    \n",
    "    if single_corner:\n",
    "        mask_corr = np.zeros_like(df_corr, dtype=bool)\n",
    "        mask_corr[np.triu_indices_from(mask_corr)] = True\n",
    "        df_corr[mask_corr] = np.nan\n",
    "        \n",
    "    sns.set(rc={'figure.figsize':(10,8)}, style='darkgrid')   \n",
    "    corr_matrix = sns.heatmap(df_corr, vmin=0, vmax=1, annot =True, cmap=\"YlGnBu\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b04536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bivariate_analysis(df, col, target=\"y\"):\n",
    "    \"\"\"\n",
    "    Plot bivariate histogram with col values and target value\n",
    "    :param df: input dataframe\n",
    "    :param col: selected column\n",
    "    :param target : name of target column (default: 'y')\n",
    "    \"\"\"\n",
    "    \n",
    "    sns.set(rc={'figure.figsize':(14,10)}, style='darkgrid')\n",
    "    \n",
    "    colors = [\"coral\", \"lightgreen\"]\n",
    "    sns.set_palette(sns.color_palette(colors))\n",
    "    \n",
    "    plt_col = sns.countplot(x=col, data = df, hue = target, order = df[col].value_counts().index)\n",
    "    \n",
    "    plt_col.tick_params(axis='x', rotation=50)\n",
    "    plt.title(f\"Relationship between {col} and {target}\",fontsize=18)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "def plot_numerical_col(df,col,target='y'):\n",
    "    \"\"\"\n",
    "    Plot bivariate boxplot and histogram with col values and target value with mean ,mode, median values\n",
    "    :param df: input dataframe\n",
    "    :param col: selected column\n",
    "    :param target : name of target column (default: 'y')\n",
    "    \"\"\"\n",
    "    \n",
    "    mean=df[col].mean()\n",
    "    median=df[col].median()\n",
    "    mode=df[col].mode().values[0]\n",
    "    \n",
    "    f, (box, hist) = plt.subplots(2, sharex=True, gridspec_kw= {\"height_ratios\": (0.3, 1)})\n",
    "    sns.set(rc={'figure.figsize':(14,10)}, style='darkgrid')\n",
    "    \n",
    "    colors = [\"coral\", \"lightgreen\"]\n",
    "    sns.set_palette(sns.color_palette(colors))\n",
    "    \n",
    "    sns.boxplot(data=df, x=col, y=target, ax=box, order = df[target].value_counts().index)\n",
    "    sns.histplot(data=df, x=col, kde=True, ax=hist)\n",
    "    \n",
    "    box.axvline(mean, color='r')\n",
    "    box.axvline(median, color='g')\n",
    "    box.axvline(mode, color='b')\n",
    "    box.set(xlabel='')\n",
    "    box.set_title(f\"Relationship between {col} and {target}\",fontsize=18)\n",
    "\n",
    "    hist.axvline(mean, color='r', label=\"Mean\")\n",
    "    hist.axvline(median, color='g', label=\"Median\")\n",
    "    hist.axvline(mode, color='b', label=\"Mode\")\n",
    "    hist.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "def plot_confusion_matrix(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix\n",
    "    :param y_pred: predicted values\n",
    "    :param y_true: true value\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_pred, y_true)\n",
    "    sns.set(rc={'figure.figsize':(8,6)}, style='darkgrid')   \n",
    "    sns.heatmap(cm, annot=True,fmt='g',cmap=\"YlGnBu\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370623ad",
   "metadata": {},
   "source": [
    "## EDA (Exploraty data analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f48086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/bank-dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00390cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47702b79",
   "metadata": {},
   "source": [
    "### Check values for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e79b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = list(df.select_dtypes(include=\"object\").columns)\n",
    "num_cols = list(df.select_dtypes(exclude=\"object\").columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6879ccc0",
   "metadata": {},
   "source": [
    "##### Object values\n",
    "\n",
    "La variabile target è molto sbilanciata sulla classe no-> 93% vs 7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bd93e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in obj_cols:\n",
    "    check_values(df,col,normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffce6faa",
   "metadata": {},
   "source": [
    "#### Normalize string column with lowercase and replace NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdaaaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in obj_cols:\n",
    "    df = normalize_col(df,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66689afa",
   "metadata": {},
   "source": [
    "#### Fix wrong values for marital values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009551ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_single = df[\"marital\"].str.startswith(\"s\")\n",
    "mask_divorced = df[\"marital\"].str.startswith(\"d\")\n",
    "\n",
    "df.loc[mask_divorced, \"marital\"] = \"divorced\"\n",
    "df.loc[mask_single, \"marital\"] = \"single\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446b9e24",
   "metadata": {},
   "source": [
    "##### Check null/nan values \n",
    "\n",
    "Le colonne **age, duration** hanno dei valori mancanti. I valori mancanti verrà sostituiti con le relative mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a2beb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = replace_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c56714",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "Non ci sono features correlate fra di loro e neanche con la variabile target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f6b27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_correlation_matrix(df, single_corner=True, target=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a599fcd7",
   "metadata": {},
   "source": [
    "### Plot bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da9f777",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    plot_numerical_col(df,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e0a2e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in obj_cols:\n",
    "    plot_bivariate_analysis(df,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff9ccb5",
   "metadata": {},
   "source": [
    "### Features selection\n",
    "\n",
    "Dai precendenti plot risulta opportuno eliminare le seguenti features: **month, day, pdays, previous**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c236d8c",
   "metadata": {},
   "source": [
    "#### Drop features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb7bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"month\", \"day\", \"pdays\", \"previous\"]\n",
    "df = df.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2e8b96",
   "metadata": {},
   "source": [
    "#### Convert binary cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c90ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = [\"default\",\"housing\",\"loan\",\"y\"]\n",
    "binary_map = {\"no\": 0, \"yes\": 1}\n",
    "\n",
    "for col in binary_cols:\n",
    "    df[col] = df[col].map(binary_map)\n",
    "    obj_cols.remove(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ec92b9",
   "metadata": {},
   "source": [
    "#### Convert categorical cols (OneHotEncoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7188355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['job', 'marital', 'contact', 'education', 'poutcome']\n",
    "df = pd.get_dummies(df, columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac14cf72",
   "metadata": {},
   "source": [
    "### Oversampling with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"y\"]\n",
    "X = df.drop(\"y\",axis = 1)\n",
    "\n",
    "sm = SMOTE()\n",
    "X_sm , y_sm = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf5b55",
   "metadata": {},
   "source": [
    "### Split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194da2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X_sm, y_sm, test_size = 0.2, random_state = 123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97229ec0",
   "metadata": {},
   "source": [
    "### Train model \n",
    "Effettuo il training con una GridSearchCV per fare il tuning di alcuni hyperparametri utilizzando la CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7315dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [None, 50],\n",
    "    \"max_features\" : ['auto', 'sqrt']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0021f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28625ce1",
   "metadata": {},
   "source": [
    "#### Best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e081705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2739e7ff",
   "metadata": {},
   "source": [
    "#### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614223db",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5f50c",
   "metadata": {},
   "source": [
    "### Predict result on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e94fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcc99aa",
   "metadata": {},
   "source": [
    "### Metriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4945a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96cfebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f6de74",
   "metadata": {},
   "source": [
    "Tutte le metriche hanno dei valori alti, dunque il modello addestrato riesce a classificare correttamente entrambe le classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f28668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast_env",
   "language": "python",
   "name": "fast_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
